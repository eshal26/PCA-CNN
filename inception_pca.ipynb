{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eshal26/PCA-CNN/blob/main/inception_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1QSl2jUy_Bon"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "import shutil\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1Db8Ci4YHAH1"
      },
      "outputs": [],
      "source": [
        "train_dir = 'train_dataset'\n",
        "val_dir = 'validation_dataset'\n",
        "test_dir = 'test_dataset'\n",
        "\n",
        "# Define transformations for training, validation, and testing data\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.8245, 0.8547, 0.9387], std = [0.1323, 0.1431, 0.0530])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.8245, 0.8547, 0.9387], std = [0.1323, 0.1431, 0.0530])\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "val_dataset = datasets.ImageFolder(root=val_dir, transform=val_test_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=val_test_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sMJdzmYeHDzM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "class SimpleInceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SimpleInceptionBlock, self).__init__()\n",
        "\n",
        "        # 3x3 convolution branch with ReLU activation\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 3x3 max pooling followed by 1x1 convolution branch with ReLU activation\n",
        "        self.branch_pool = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, 16, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch3x3_out = self.branch3x3(x)\n",
        "        branch_pool_out = self.branch_pool(x)\n",
        "        outputs = [branch3x3_out, branch_pool_out]\n",
        "        return torch.cat(outputs, 1)  # Concatenate along channel dimension\n",
        "\n",
        "class SimpleInceptionModelWithPCA(nn.Module):\n",
        "    def __init__(self, pca_components=10, pca=None):\n",
        "        super(SimpleInceptionModelWithPCA, self).__init__()\n",
        "\n",
        "        # Initial convolutional layer with increased stride for feature size reduction\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # Stride set to 2\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Inception block\n",
        "        self.inception = SimpleInceptionBlock(16)\n",
        "\n",
        "        # Add aggressive pooling after inception block\n",
        "        self.pool = nn.AdaptiveAvgPool2d((4, 4))  # Reduce output spatial size to 4x4\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        # PCA Parameters\n",
        "        self.pca = pca  # Accept PCA instance externally or set to None\n",
        "        self.pca_components = pca_components\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(self.pca_components, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)  # Output layer for binary classification\n",
        "\n",
        "    def _get_flatten_size(self):\n",
        "        # Dynamically compute the flatten size by passing a dummy tensor\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
        "            x = self.conv1(dummy_input)\n",
        "            x = self.inception(x)\n",
        "            x = self.pool(x)\n",
        "            x = self.flatten(x)\n",
        "        return x.shape[1]\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        \"\"\"Extract features before passing them to fully connected layers.\"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.inception(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.extract_features(x)\n",
        "        device = x.device\n",
        "\n",
        "        # Apply PCA if it is fitted\n",
        "        if self.pca is not None:\n",
        "            x_cpu = x.detach().cpu().numpy()  # Convert tensor to NumPy array\n",
        "            x_pca = self.pca.transform(x_cpu)  # Apply PCA transformation\n",
        "            x = torch.from_numpy(x_pca).to(device, dtype=torch.float32)  # Back to PyTorch tensor\n",
        "        else:\n",
        "            raise RuntimeError(\"PCA must be fitted before the forward pass\")\n",
        "\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc1(x)\n",
        "        x = nn.ReLU()(x)  # Apply ReLU activation after the first fully connected layer\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def fit_pca(self, dataloader, num_components=10):\n",
        "        \"\"\"\n",
        "        Fit PCA on the extracted features of the model.\n",
        "        \"\"\"\n",
        "        self.eval()  # Ensure model is in eval mode\n",
        "        features = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, _ in dataloader:\n",
        "                inputs = inputs.to(next(self.parameters()).device)\n",
        "                x = self.extract_features(inputs)\n",
        "                features.append(x.cpu().numpy())\n",
        "\n",
        "        features = np.vstack(features)  # Combine all features\n",
        "        pca = PCA(n_components=num_components)\n",
        "        pca.fit(features)\n",
        "        self.pca = pca  # Assign the fitted PCA to the model\n",
        "\n",
        "\n",
        "\n",
        "model = SimpleInceptionModelWithPCA(pca_components=10)\n",
        "\n",
        "# Assume train_loader is a DataLoader that provides batches of training data\n",
        "model.fit_pca(train_loader, num_components=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nUoTB2XYHKbN",
        "outputId": "87b49903-22d0-4087-fd2e-480189c2e3aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (32x32 and 10x64)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-85ff9708966f>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-85ff9708966f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d9d1f8f6a1a3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply ReLU activation after the first fully connected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x32 and 10x64)"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    model.to(device)\n",
        "\n",
        "    # Step 1: Fit PCA on training data\n",
        "    model.fit_pca(train_loader, num_components=model.pca_components)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track statistics\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "        train_loss = running_loss / total_samples\n",
        "        train_acc = running_corrects.double() / total_samples\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        val_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Track statistics\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "                val_samples += inputs.size(0)\n",
        "\n",
        "        val_loss = val_loss / val_samples\n",
        "        val_acc = val_corrects.double() / val_samples\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 30\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "        model (torch.nn.Module): Trained model to evaluate.\n",
        "        test_loader (DataLoader): DataLoader for the test dataset.\n",
        "        criterion (loss function): Loss function used during training.\n",
        "        device (torch.device): Device to perform computation on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing test loss, accuracy, and optionally other metrics.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Accumulate loss\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Accumulate correct predictions\n",
        "            correct_preds += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            # Collect predictions and labels for detailed metrics\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    # Compute average loss and accuracy\n",
        "    avg_loss = test_loss / total_samples\n",
        "    accuracy = correct_preds.double() / total_samples\n",
        "\n",
        "    # Compute detailed metrics\n",
        "    class_report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return {\n",
        "        \"loss\": avg_loss,\n",
        "        \"accuracy\": accuracy.item(),\n",
        "        \"classification_report\": class_report,\n",
        "        \"confusion_matrix\": conf_matrix,\n",
        "    }\n",
        "\n",
        "# Example Usage:\n",
        "# Assuming `test_loader` is a DataLoader for your test dataset\n",
        "test_results = evaluate_model(trained_model, test_loader, criterion, device)\n"
      ],
      "metadata": {
        "id": "UZBlPJDcPOTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def plot_pca_features(model, dataloader, num_components=2):\n",
        "    \"\"\"\n",
        "    Extract features using the model, transform them with PCA, and plot in 2D/3D.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    # Extract features and labels\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs = inputs.to(next(model.parameters()).device)\n",
        "            x = model.extract_features(inputs)\n",
        "            features.append(x.cpu().numpy())\n",
        "            labels.append(targets.cpu().numpy())\n",
        "\n",
        "    # Combine all features and labels\n",
        "    features = np.vstack(features)\n",
        "    labels = np.concatenate(labels)\n",
        "\n",
        "    # Apply PCA for visualization\n",
        "    pca = PCA(n_components=num_components)\n",
        "    transformed_features = pca.fit_transform(features)\n",
        "\n",
        "    # 2D Plot\n",
        "    if num_components == 2:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.scatterplot(\n",
        "            x=transformed_features[:, 0],\n",
        "            y=transformed_features[:, 1],\n",
        "            hue=labels,\n",
        "            palette=\"Set2\",\n",
        "            s=50,\n",
        "        )\n",
        "        plt.title(\"PCA Feature Visualization (2D)\")\n",
        "        plt.xlabel(\"PCA Component 1\")\n",
        "        plt.ylabel(\"PCA Component 2\")\n",
        "        plt.legend(title=\"Classes\")\n",
        "        plt.show()\n",
        "\n",
        "    # 3D Plot\n",
        "    elif num_components == 3:\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        ax = fig.add_subplot(111, projection=\"3d\")\n",
        "        scatter = ax.scatter(\n",
        "            transformed_features[:, 0],\n",
        "            transformed_features[:, 1],\n",
        "            transformed_features[:, 2],\n",
        "            c=labels,\n",
        "            cmap=\"Set2\",\n",
        "            s=50,\n",
        "        )\n",
        "        ax.set_title(\"PCA Feature Visualization (3D)\")\n",
        "        ax.set_xlabel(\"PCA Component 1\")\n",
        "        ax.set_ylabel(\"PCA Component 2\")\n",
        "        ax.set_zlabel(\"PCA Component 3\")\n",
        "        legend = ax.legend(*scatter.legend_elements(), title=\"Classes\")\n",
        "        ax.add_artist(legend)\n",
        "        plt.show()\n",
        "    else:\n",
        "        raise ValueError(\"num_components must be 2 or 3 for visualization.\")\n",
        "\n",
        "# Assuming `model` is trained, and `train_loader` or `test_loader` is available\n",
        "plot_pca_features(model, train_loader, num_components=2)  # 2D plot\n",
        "plot_pca_features(model, train_loader, num_components=3)  # 3D plot\n"
      ],
      "metadata": {
        "id": "gY_P9bC3PZ3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Step 1: Extract PCA-Transformed Features from Model\n",
        "pca_features = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in train_loader:  # Assuming `train_loader` is defined\n",
        "        inputs = inputs.to(next(model.parameters()).device)\n",
        "\n",
        "        # Extract raw features\n",
        "        raw_features = model.extract_features(inputs)\n",
        "\n",
        "        # Apply PCA transformation\n",
        "        transformed_features = model.pca.transform(raw_features.cpu().numpy())\n",
        "        pca_features.append(transformed_features)\n",
        "\n",
        "# Combine all features into a single array\n",
        "pca_features = np.vstack(pca_features)\n",
        "\n",
        "# Step 2: Create a DataFrame\n",
        "pca_features_df = pd.DataFrame(pca_features, columns=[f\"PC{i+1}\" for i in range(pca_features.shape[1])])\n",
        "\n",
        "# Step 3: Compute Correlation Matrix\n",
        "correlation_matrix = pca_features_df.corr()\n",
        "\n",
        "# Step 4: Plot Heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=True, fmt=\".2f\", cbar=True)\n",
        "plt.title(\"PCA-Transformed Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bW81nTIVPgmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jj-6DUZhPkiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMO4DPINRxs/4WDYTi3ZNXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}